[32m[08/12 18:35:34 d2.engine.defaults]: [39mModel:
PanopticDeepLab(
  (backbone): ResNet(
    (stem): DeepLabStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (conv2): Conv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (conv3): Conv2d(
        64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): PanopticDeepLabSemSegHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): Sequential(
          (0): Conv2d(
            288, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): Sequential(
          (0): Conv2d(
            320, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): Conv2d(
              2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False
              (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): Conv2d(
              2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False
              (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): Conv2d(
              2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False
              (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(32, 32), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (head): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (predictor): Conv2d(256, 9, kernel_size=(1, 1), stride=(1, 1))
    (loss): DeepLabCE(
      (criterion): CrossEntropyLoss()
    )
  )
  (ins_embed_head): PanopticDeepLabInsEmbedHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): Sequential(
          (0): Conv2d(
            160, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): Sequential(
          (0): Conv2d(
            320, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): Conv2d(
              2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False
              (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): Conv2d(
              2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False
              (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): Conv2d(
              2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False
              (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(32, 32), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (center_head): Sequential(
      (0): Conv2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): Conv2d(
        128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (center_predictor): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))
    (offset_head): Sequential(
      (0): Conv2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): Conv2d(
        128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (offset_predictor): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))
    (center_loss): MSELoss()
    (offset_loss): L1Loss()
  )
)
[32m[08/12 18:35:34 d2.projects.panoptic_deeplab.dataset_mapper]: [39mAugmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=2048, sample_style='choice'), RandomCrop(crop_type='absolute', crop_size=[512, 512]), RandomFlip(), RandomBrightness(intensity_min=0.5, intensity_max=1.5), RandomContrast(intensity_min=0.5, intensity_max=1.5)]
[32m[08/12 18:35:35 d2.data.build]: [39mUsing training sampler TrainingSampler
[32m[08/12 18:35:35 d2.data.common]: [39mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[32m[08/12 18:35:35 d2.data.common]: [39mSerializing 276 elements to byte tensors and concatenating them all ...
[32m[08/12 18:35:35 d2.data.common]: [39mSerialized dataset takes 1.33 MiB
[32m[08/12 18:35:35 d2.data.build]: [39mMaking batched data loader with batch_size=8
[32m[08/12 18:35:35 d2.checkpoint.detection_checkpoint]: [39m[DetectionCheckpointer] Loading from detectron2://DeepLab/R-52.pkl ...
[32m[08/12 18:35:35 fvcore.common.checkpoint]: [39m[Checkpointer] Loading from /home/liwa/.torch/iopath_cache/detectron2/DeepLab/R-52.pkl ...
[32m[08/12 18:35:35 fvcore.common.checkpoint]: [39mReading a file from 'torchvision'
[32m[08/12 18:35:35 d2.checkpoint.c2_model_loading]: [39mFollowing weights matched with submodule backbone - Total num: 55
[31m[5mWARNING[39m[25m [32m[08/12 18:35:35 fvcore.common.checkpoint]: [39mSome model parameters or buffers are not found in the checkpoint:
[34mins_embed_head.center_head.0.norm.{bias, running_mean, running_var, weight}
[34mins_embed_head.center_head.0.weight
[34mins_embed_head.center_head.1.norm.{bias, running_mean, running_var, weight}
[34mins_embed_head.center_head.1.weight
[34mins_embed_head.center_predictor.{bias, weight}
[34mins_embed_head.decoder.res2.fuse_conv.0.norm.{bias, running_mean, running_var, weight}
[34mins_embed_head.decoder.res2.fuse_conv.0.weight
[34mins_embed_head.decoder.res2.fuse_conv.1.norm.{bias, running_mean, running_var, weight}
[34mins_embed_head.decoder.res2.fuse_conv.1.weight
[34mins_embed_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}
[34mins_embed_head.decoder.res2.project_conv.weight
[34mins_embed_head.decoder.res3.fuse_conv.0.norm.{bias, running_mean, running_var, weight}
[34mins_embed_head.decoder.res3.fuse_conv.0.weight
[34mins_embed_head.decoder.res3.fuse_conv.1.norm.{bias, running_mean, running_var, weight}
[34mins_embed_head.decoder.res3.fuse_conv.1.weight
[34mins_embed_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}
[34mins_embed_head.decoder.res3.project_conv.weight
[34mins_embed_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}
[34mins_embed_head.decoder.res5.project_conv.convs.0.weight
[34mins_embed_head.decoder.res5.project_conv.convs.1.norm.{bias, running_mean, running_var, weight}
[34mins_embed_head.decoder.res5.project_conv.convs.1.weight
[34mins_embed_head.decoder.res5.project_conv.convs.2.norm.{bias, running_mean, running_var, weight}
[34mins_embed_head.decoder.res5.project_conv.convs.2.weight
[34mins_embed_head.decoder.res5.project_conv.convs.3.norm.{bias, running_mean, running_var, weight}
[34mins_embed_head.decoder.res5.project_conv.convs.3.weight
[34mins_embed_head.decoder.res5.project_conv.convs.4.1.{bias, weight}
[34mins_embed_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}
[34mins_embed_head.decoder.res5.project_conv.project.weight
[34mins_embed_head.offset_head.0.norm.{bias, running_mean, running_var, weight}
[34mins_embed_head.offset_head.0.weight
[34mins_embed_head.offset_head.1.norm.{bias, running_mean, running_var, weight}
[34mins_embed_head.offset_head.1.weight
[34mins_embed_head.offset_predictor.{bias, weight}
[34msem_seg_head.decoder.res2.fuse_conv.0.norm.{bias, running_mean, running_var, weight}
[34msem_seg_head.decoder.res2.fuse_conv.0.weight
[34msem_seg_head.decoder.res2.fuse_conv.1.norm.{bias, running_mean, running_var, weight}
[34msem_seg_head.decoder.res2.fuse_conv.1.weight
[34msem_seg_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}
[34msem_seg_head.decoder.res2.project_conv.weight
[34msem_seg_head.decoder.res3.fuse_conv.0.norm.{bias, running_mean, running_var, weight}
[34msem_seg_head.decoder.res3.fuse_conv.0.weight
[34msem_seg_head.decoder.res3.fuse_conv.1.norm.{bias, running_mean, running_var, weight}
[34msem_seg_head.decoder.res3.fuse_conv.1.weight
[34msem_seg_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}
[34msem_seg_head.decoder.res3.project_conv.weight
[34msem_seg_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}
[34msem_seg_head.decoder.res5.project_conv.convs.0.weight
[34msem_seg_head.decoder.res5.project_conv.convs.1.norm.{bias, running_mean, running_var, weight}
[34msem_seg_head.decoder.res5.project_conv.convs.1.weight
[34msem_seg_head.decoder.res5.project_conv.convs.2.norm.{bias, running_mean, running_var, weight}
[34msem_seg_head.decoder.res5.project_conv.convs.2.weight
[34msem_seg_head.decoder.res5.project_conv.convs.3.norm.{bias, running_mean, running_var, weight}
[34msem_seg_head.decoder.res5.project_conv.convs.3.weight
[34msem_seg_head.decoder.res5.project_conv.convs.4.1.{bias, weight}
[34msem_seg_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}
[34msem_seg_head.decoder.res5.project_conv.project.weight
[34msem_seg_head.head.0.norm.{bias, running_mean, running_var, weight}
[34msem_seg_head.head.0.weight
[34msem_seg_head.head.1.norm.{bias, running_mean, running_var, weight}
[34msem_seg_head.head.1.weight
[34msem_seg_head.predictor.{bias, weight}
[31m[5mWARNING[39m[25m [32m[08/12 18:35:35 fvcore.common.checkpoint]: [39mThe checkpoint state_dict contains keys that are not used by the model:
  [35mstem.fc.{bias, weight}
[32m[08/12 18:35:35 d2.engine.train_loop]: [39mStarting training from iteration 0
[32m[08/12 18:36:43 d2.utils.events]: [39m eta: 3 days, 12:39:28  iter: 19  total_loss: 147.6  loss_sem_seg: 22.06  loss_center: 125.2  loss_offset: 0.2873    time: 1.5323  last_time: 1.6720  data_time: 2.0674  last_data_time: 0.5150   lr: 9.9896e-06  max_mem: 8671M
[32m[08/12 18:37:14 d2.utils.events]: [39m eta: 3 days, 12:33:24  iter: 39  total_loss: 141.4  loss_sem_seg: 21.85  loss_center: 119.3  loss_offset: 0.2663    time: 1.5366  last_time: 1.6288  data_time: 0.2755  last_data_time: 0.3726   lr: 1.9977e-05  max_mem: 8671M
[32m[08/12 18:37:46 d2.utils.events]: [39m eta: 3 days, 14:31:36  iter: 59  total_loss: 120.6  loss_sem_seg: 21.41  loss_center: 98.78  loss_offset: 0.2795    time: 1.5669  last_time: 1.6982  data_time: 0.3023  last_data_time: 0.3764   lr: 2.9963e-05  max_mem: 8671M
[32m[08/12 18:38:18 d2.utils.events]: [39m eta: 3 days, 14:55:24  iter: 79  total_loss: 114.5  loss_sem_seg: 20.59  loss_center: 93.64  loss_offset: 0.2698    time: 1.5752  last_time: 1.4810  data_time: 0.2564  last_data_time: 0.2227   lr: 3.9946e-05  max_mem: 8671M
[32m[08/12 18:38:51 d2.utils.events]: [39m eta: 3 days, 15:32:33  iter: 99  total_loss: 90.41  loss_sem_seg: 19.46  loss_center: 70.48  loss_offset: 0.279    time: 1.5867  last_time: 1.6416  data_time: 0.2715  last_data_time: 0.2927   lr: 4.9928e-05  max_mem: 8671M
[32m[08/12 18:39:22 d2.utils.events]: [39m eta: 3 days, 15:18:56  iter: 119  total_loss: 73.64  loss_sem_seg: 18.4  loss_center: 55.05  loss_offset: 0.2776    time: 1.5801  last_time: 1.7350  data_time: 0.2645  last_data_time: 0.3198   lr: 5.9908e-05  max_mem: 8671M
[32m[08/12 18:39:56 d2.utils.events]: [39m eta: 3 days, 16:24:49  iter: 139  total_loss: 56.9  loss_sem_seg: 17.27  loss_center: 39.89  loss_offset: 0.2588    time: 1.5970  last_time: 1.7806  data_time: 0.3131  last_data_time: 0.3024   lr: 6.9887e-05  max_mem: 8671M
[32m[08/12 18:40:28 d2.utils.events]: [39m eta: 3 days, 16:08:24  iter: 159  total_loss: 40.31  loss_sem_seg: 16.25  loss_center: 23.77  loss_offset: 0.263    time: 1.5979  last_time: 1.6447  data_time: 0.2765  last_data_time: 0.3138   lr: 7.9863e-05  max_mem: 8671M
[32m[08/12 18:41:00 d2.utils.events]: [39m eta: 3 days, 16:07:52  iter: 179  total_loss: 31.85  loss_sem_seg: 15.53  loss_center: 16.94  loss_offset: 0.2517    time: 1.6013  last_time: 1.5580  data_time: 0.2869  last_data_time: 0.2942   lr: 8.9838e-05  max_mem: 8671M
[32m[08/12 18:41:32 d2.utils.events]: [39m eta: 3 days, 16:02:24  iter: 199  total_loss: 28.52  loss_sem_seg: 14.45  loss_center: 13.52  loss_offset: 0.2541    time: 1.6012  last_time: 1.7951  data_time: 0.2668  last_data_time: 0.4026   lr: 9.9811e-05  max_mem: 8671M
[32m[08/12 18:42:05 d2.utils.events]: [39m eta: 3 days, 16:12:15  iter: 219  total_loss: 26.11  loss_sem_seg: 14.1  loss_center: 11.61  loss_offset: 0.2387    time: 1.6032  last_time: 1.5128  data_time: 0.2870  last_data_time: 0.3027   lr: 0.00010978  max_mem: 8671M
[32m[08/12 18:42:37 d2.utils.events]: [39m eta: 3 days, 16:04:25  iter: 239  total_loss: 23.44  loss_sem_seg: 12.89  loss_center: 10.23  loss_offset: 0.2263    time: 1.6024  last_time: 1.5804  data_time: 0.2757  last_data_time: 0.2419   lr: 0.00011975  max_mem: 8671M
[32m[08/12 18:43:09 d2.utils.events]: [39m eta: 3 days, 16:07:56  iter: 259  total_loss: 21.55  loss_sem_seg: 12.09  loss_center: 9.285  loss_offset: 0.2425    time: 1.6038  last_time: 1.7725  data_time: 0.2741  last_data_time: 0.3293   lr: 0.00012972  max_mem: 8671M
[32m[08/12 18:43:41 d2.utils.events]: [39m eta: 3 days, 16:08:49  iter: 279  total_loss: 21.37  loss_sem_seg: 11.5  loss_center: 9.662  loss_offset: 0.2353    time: 1.6044  last_time: 1.6235  data_time: 0.2742  last_data_time: 0.2598   lr: 0.00013968  max_mem: 8671M
[32m[08/12 18:44:13 d2.utils.events]: [39m eta: 3 days, 16:05:56  iter: 299  total_loss: 19.33  loss_sem_seg: 10.73  loss_center: 8.164  loss_offset: 0.2288    time: 1.6043  last_time: 1.5678  data_time: 0.2856  last_data_time: 0.2409   lr: 0.00014965  max_mem: 8671M
[32m[08/12 18:44:46 d2.utils.events]: [39m eta: 3 days, 16:14:06  iter: 319  total_loss: 17.66  loss_sem_seg: 10.07  loss_center: 7.381  loss_offset: 0.2159    time: 1.6063  last_time: 1.5344  data_time: 0.3062  last_data_time: 0.2311   lr: 0.00015961  max_mem: 8671M
[32m[08/12 18:45:19 d2.utils.events]: [39m eta: 3 days, 16:17:52  iter: 339  total_loss: 16.79  loss_sem_seg: 9.417  loss_center: 7.749  loss_offset: 0.2153    time: 1.6080  last_time: 1.7401  data_time: 0.2841  last_data_time: 0.3792   lr: 0.00016957  max_mem: 8671M
[32m[08/12 18:45:51 d2.utils.events]: [39m eta: 3 days, 16:18:58  iter: 359  total_loss: 16.69  loss_sem_seg: 8.935  loss_center: 7.694  loss_offset: 0.2068    time: 1.6075  last_time: 1.6938  data_time: 0.2757  last_data_time: 0.2337   lr: 0.00017953  max_mem: 8671M
[32m[08/12 18:46:23 d2.utils.events]: [39m eta: 3 days, 16:16:49  iter: 379  total_loss: 15.34  loss_sem_seg: 8.344  loss_center: 6.956  loss_offset: 0.2089    time: 1.6073  last_time: 1.7048  data_time: 0.2799  last_data_time: 0.2729   lr: 0.00018949  max_mem: 8671M
[32m[08/12 18:46:55 d2.utils.events]: [39m eta: 3 days, 16:17:55  iter: 399  total_loss: 14.81  loss_sem_seg: 7.806  loss_center: 6.811  loss_offset: 0.201    time: 1.6080  last_time: 1.5778  data_time: 0.2830  last_data_time: 0.2665   lr: 0.00019944  max_mem: 8671M
[32m[08/12 18:47:28 d2.utils.events]: [39m eta: 3 days, 16:21:27  iter: 419  total_loss: 16.3  loss_sem_seg: 7.639  loss_center: 8.093  loss_offset: 0.1933    time: 1.6089  last_time: 1.6370  data_time: 0.2911  last_data_time: 0.2352   lr: 0.00020939  max_mem: 8671M
[32m[08/12 18:48:00 d2.utils.events]: [39m eta: 3 days, 16:23:53  iter: 439  total_loss: 15.86  loss_sem_seg: 8.01  loss_center: 8.328  loss_offset: 0.1808    time: 1.6098  last_time: 1.8088  data_time: 0.3242  last_data_time: 0.6311   lr: 0.00021935  max_mem: 8671M
[32m[08/12 18:48:33 d2.utils.events]: [39m eta: 3 days, 16:23:34  iter: 459  total_loss: 14.77  loss_sem_seg: 7.187  loss_center: 7.354  loss_offset: 0.1713    time: 1.6099  last_time: 1.6407  data_time: 0.2832  last_data_time: 0.2642   lr: 0.0002293  max_mem: 8671M
[32m[08/12 18:49:04 d2.utils.events]: [39m eta: 3 days, 16:16:53  iter: 479  total_loss: 14.39  loss_sem_seg: 7.314  loss_center: 6.827  loss_offset: 0.1792    time: 1.6088  last_time: 1.4537  data_time: 0.2729  last_data_time: 0.2197   lr: 0.00023924  max_mem: 8671M
[32m[08/12 18:49:36 d2.utils.events]: [39m eta: 3 days, 16:15:48  iter: 499  total_loss: 14.13  loss_sem_seg: 7.107  loss_center: 6.735  loss_offset: 0.1621    time: 1.6076  last_time: 1.6993  data_time: 0.2894  last_data_time: 0.2873   lr: 0.00024919  max_mem: 8671M
[32m[08/12 18:50:09 d2.utils.events]: [39m eta: 3 days, 16:15:41  iter: 519  total_loss: 13.69  loss_sem_seg: 6.675  loss_center: 6.718  loss_offset: 0.1586    time: 1.6093  last_time: 1.5549  data_time: 0.2992  last_data_time: 0.2385   lr: 0.00025913  max_mem: 8671M
[32m[08/12 18:50:41 d2.utils.events]: [39m eta: 3 days, 16:15:09  iter: 539  total_loss: 13.14  loss_sem_seg: 6.798  loss_center: 6.715  loss_offset: 0.1481    time: 1.6097  last_time: 1.5262  data_time: 0.2773  last_data_time: 0.1985   lr: 0.00026908  max_mem: 8671M
[32m[08/12 18:51:13 d2.utils.events]: [39m eta: 3 days, 16:14:12  iter: 559  total_loss: 13.66  loss_sem_seg: 6.722  loss_center: 6.568  loss_offset: 0.1469    time: 1.6085  last_time: 1.6770  data_time: 0.2618  last_data_time: 0.2652   lr: 0.00027902  max_mem: 8671M
[32m[08/12 18:51:47 d2.utils.events]: [39m eta: 3 days, 16:20:02  iter: 579  total_loss: 12.01  loss_sem_seg: 6.462  loss_center: 5.891  loss_offset: 0.1318    time: 1.6111  last_time: 2.0294  data_time: 0.2760  last_data_time: 0.2637   lr: 0.00028896  max_mem: 8671M
[32m[08/12 18:52:19 d2.utils.events]: [39m eta: 3 days, 16:19:30  iter: 599  total_loss: 11.96  loss_sem_seg: 6.198  loss_center: 5.311  loss_offset: 0.1272    time: 1.6111  last_time: 1.5841  data_time: 0.2775  last_data_time: 0.2427   lr: 0.00029889  max_mem: 8671M
[32m[08/12 18:52:50 d2.utils.events]: [39m eta: 3 days, 16:13:01  iter: 619  total_loss: 12.33  loss_sem_seg: 5.993  loss_center: 5.746  loss_offset: 0.1321    time: 1.6097  last_time: 1.6187  data_time: 0.2626  last_data_time: 0.3043   lr: 0.00030883  max_mem: 8671M
[32m[08/12 18:53:23 d2.utils.events]: [39m eta: 3 days, 16:12:29  iter: 639  total_loss: 11.91  loss_sem_seg: 6.157  loss_center: 5.289  loss_offset: 0.1212    time: 1.6101  last_time: 1.5857  data_time: 0.3001  last_data_time: 0.3373   lr: 0.00031876  max_mem: 8671M
[32m[08/12 18:53:55 d2.utils.events]: [39m eta: 3 days, 16:14:41  iter: 659  total_loss: 13.17  loss_sem_seg: 6.034  loss_center: 6.725  loss_offset: 0.125    time: 1.6105  last_time: 1.6611  data_time: 0.2719  last_data_time: 0.1987   lr: 0.00032869  max_mem: 8671M
[32m[08/12 18:54:27 d2.utils.events]: [39m eta: 3 days, 16:15:48  iter: 679  total_loss: 13.43  loss_sem_seg: 6.271  loss_center: 7.089  loss_offset: 0.1293    time: 1.6105  last_time: 1.6290  data_time: 0.2816  last_data_time: 0.2573   lr: 0.00033862  max_mem: 8671M
[32m[08/12 18:54:59 d2.utils.events]: [39m eta: 3 days, 16:13:38  iter: 699  total_loss: 11.72  loss_sem_seg: 5.894  loss_center: 5.594  loss_offset: 0.1181    time: 1.6096  last_time: 1.6079  data_time: 0.2599  last_data_time: 0.2228   lr: 0.00034855  max_mem: 8671M
[32m[08/12 18:55:32 d2.utils.events]: [39m eta: 3 days, 16:16:27  iter: 719  total_loss: 10.99  loss_sem_seg: 5.837  loss_center: 5.372  loss_offset: 0.1077    time: 1.6104  last_time: 1.5445  data_time: 0.3059  last_data_time: 0.2800   lr: 0.00035848  max_mem: 8671M
[32m[08/12 18:56:04 d2.utils.events]: [39m eta: 3 days, 16:15:55  iter: 739  total_loss: 11.16  loss_sem_seg: 5.865  loss_center: 5.231  loss_offset: 0.1135    time: 1.6106  last_time: 1.5757  data_time: 0.3022  last_data_time: 0.2400   lr: 0.0003684  max_mem: 8671M
[32m[08/12 18:56:36 d2.utils.events]: [39m eta: 3 days, 16:13:41  iter: 759  total_loss: 12.11  loss_sem_seg: 5.752  loss_center: 5.918  loss_offset: 0.1211    time: 1.6098  last_time: 1.6618  data_time: 0.2669  last_data_time: 0.3897   lr: 0.00037832  max_mem: 8671M
[32m[08/12 18:57:08 d2.utils.events]: [39m eta: 3 days, 16:14:51  iter: 779  total_loss: 11.12  loss_sem_seg: 5.58  loss_center: 5.067  loss_offset: 0.1093    time: 1.6103  last_time: 1.6352  data_time: 0.2846  last_data_time: 0.2417   lr: 0.00038824  max_mem: 8671M
[32m[08/12 18:57:42 d2.utils.events]: [39m eta: 3 days, 16:17:39  iter: 799  total_loss: 11.12  loss_sem_seg: 5.328  loss_center: 5.211  loss_offset: 0.09521    time: 1.6115  last_time: 1.6032  data_time: 0.2851  last_data_time: 0.2228   lr: 0.00039816  max_mem: 8671M
[32m[08/12 18:58:13 d2.utils.events]: [39m eta: 3 days, 16:14:00  iter: 819  total_loss: 10.83  loss_sem_seg: 5.548  loss_center: 5.417  loss_offset: 0.0941    time: 1.6103  last_time: 1.6114  data_time: 0.2585  last_data_time: 0.3182   lr: 0.00040808  max_mem: 8671M
[32m[08/12 18:58:46 d2.utils.events]: [39m eta: 3 days, 16:13:28  iter: 839  total_loss: 10.62  loss_sem_seg: 5.292  loss_center: 5.184  loss_offset: 0.09812    time: 1.6110  last_time: 1.5787  data_time: 0.3032  last_data_time: 0.1986   lr: 0.000418  max_mem: 8671M
[32m[08/12 18:59:19 d2.utils.events]: [39m eta: 3 days, 16:16:03  iter: 859  total_loss: 10.18  loss_sem_seg: 4.841  loss_center: 5.044  loss_offset: 0.09829    time: 1.6121  last_time: 1.7163  data_time: 0.2978  last_data_time: 0.3702   lr: 0.00042791  max_mem: 8671M
[32m[08/12 18:59:51 d2.utils.events]: [39m eta: 3 days, 16:14:07  iter: 879  total_loss: 10.19  loss_sem_seg: 5.163  loss_center: 4.629  loss_offset: 0.09479    time: 1.6116  last_time: 1.5594  data_time: 0.2737  last_data_time: 0.2343   lr: 0.00043782  max_mem: 8671M
[32m[08/12 19:00:22 d2.utils.events]: [39m eta: 3 days, 16:13:10  iter: 899  total_loss: 10.08  loss_sem_seg: 5.058  loss_center: 4.987  loss_offset: 0.08671    time: 1.6109  last_time: 1.6390  data_time: 0.2815  last_data_time: 0.3161   lr: 0.00044773  max_mem: 8671M
[32m[08/12 19:00:56 d2.utils.events]: [39m eta: 3 days, 16:13:28  iter: 919  total_loss: 10.09  loss_sem_seg: 5.067  loss_center: 4.465  loss_offset: 0.08777    time: 1.6120  last_time: 1.5571  data_time: 0.3187  last_data_time: 0.2375   lr: 0.00045764  max_mem: 8671M
[32m[08/12 19:01:27 d2.utils.events]: [39m eta: 3 days, 16:12:56  iter: 939  total_loss: 9.591  loss_sem_seg: 4.907  loss_center: 4.541  loss_offset: 0.07852    time: 1.6117  last_time: 1.6029  data_time: 0.2809  last_data_time: 0.3867   lr: 0.00046755  max_mem: 8671M
[32m[08/12 19:01:59 d2.utils.events]: [39m eta: 3 days, 16:11:35  iter: 959  total_loss: 9.697  loss_sem_seg: 4.901  loss_center: 4.521  loss_offset: 0.07849    time: 1.6115  last_time: 1.6258  data_time: 0.2733  last_data_time: 0.2501   lr: 0.00047745  max_mem: 8671M
[32m[08/12 19:02:32 d2.utils.events]: [39m eta: 3 days, 16:11:28  iter: 979  total_loss: 9.439  loss_sem_seg: 4.796  loss_center: 4.417  loss_offset: 0.0854    time: 1.6115  last_time: 1.5648  data_time: 0.2798  last_data_time: 0.2832   lr: 0.00048735  max_mem: 8671M
[32m[08/12 19:03:04 d2.utils.events]: [39m eta: 3 days, 16:11:21  iter: 999  total_loss: 8.767  loss_sem_seg: 4.701  loss_center: 4.131  loss_offset: 0.07384    time: 1.6116  last_time: 1.4783  data_time: 0.2852  last_data_time: 0.1742   lr: 0.00049725  max_mem: 8671M
[32m[08/12 19:03:36 d2.utils.events]: [39m eta: 3 days, 16:11:48  iter: 1019  total_loss: 8.715  loss_sem_seg: 4.519  loss_center: 4.046  loss_offset: 0.07302    time: 1.6112  last_time: 1.5767  data_time: 0.2704  last_data_time: 0.3132   lr: 0.00049771  max_mem: 8671M
[32m[08/12 19:04:08 d2.utils.events]: [39m eta: 3 days, 16:15:27  iter: 1039  total_loss: 9.384  loss_sem_seg: 4.986  loss_center: 4.446  loss_offset: 0.0721    time: 1.6109  last_time: 1.5750  data_time: 0.2905  last_data_time: 0.2788   lr: 0.00049766  max_mem: 8671M
[32m[08/12 19:04:40 d2.utils.events]: [39m eta: 3 days, 16:11:46  iter: 1059  total_loss: 8.932  loss_sem_seg: 4.842  loss_center: 4.248  loss_offset: 0.07183    time: 1.6107  last_time: 1.6756  data_time: 0.2853  last_data_time: 0.2694   lr: 0.00049762  max_mem: 8671M
[32m[08/12 19:05:12 d2.utils.events]: [39m eta: 3 days, 16:14:23  iter: 1079  total_loss: 8.236  loss_sem_seg: 4.296  loss_center: 3.77  loss_offset: 0.07114    time: 1.6110  last_time: 1.6606  data_time: 0.2851  last_data_time: 0.3031   lr: 0.00049757  max_mem: 8671M
[32m[08/12 19:05:44 d2.utils.events]: [39m eta: 3 days, 16:11:07  iter: 1099  total_loss: 9.298  loss_sem_seg: 4.636  loss_center: 4.319  loss_offset: 0.07289    time: 1.6102  last_time: 1.5611  data_time: 0.2735  last_data_time: 0.2543   lr: 0.00049753  max_mem: 8671M
[32m[08/12 19:06:16 d2.utils.events]: [39m eta: 3 days, 16:11:06  iter: 1119  total_loss: 8.162  loss_sem_seg: 4.462  loss_center: 3.841  loss_offset: 0.07294    time: 1.6102  last_time: 1.4983  data_time: 0.2954  last_data_time: 0.2496   lr: 0.00049748  max_mem: 8671M
[32m[08/12 19:06:50 d2.utils.events]: [39m eta: 3 days, 16:09:38  iter: 1139  total_loss: 8.393  loss_sem_seg: 4.45  loss_center: 3.751  loss_offset: 0.0695    time: 1.6116  last_time: 1.5442  data_time: 0.2921  last_data_time: 0.2725   lr: 0.00049744  max_mem: 8671M
[32m[08/12 19:07:22 d2.utils.events]: [39m eta: 3 days, 16:09:06  iter: 1159  total_loss: 8.108  loss_sem_seg: 4.336  loss_center: 3.693  loss_offset: 0.06864    time: 1.6113  last_time: 1.5488  data_time: 0.2576  last_data_time: 0.1965   lr: 0.00049739  max_mem: 8671M
[32m[08/12 19:07:54 d2.utils.events]: [39m eta: 3 days, 16:09:00  iter: 1179  total_loss: 8.412  loss_sem_seg: 4.452  loss_center: 4.108  loss_offset: 0.0639    time: 1.6112  last_time: 1.5304  data_time: 0.2887  last_data_time: 0.2348   lr: 0.00049735  max_mem: 8671M
[32m[08/12 19:08:26 d2.utils.events]: [39m eta: 3 days, 16:10:24  iter: 1199  total_loss: 8.509  loss_sem_seg: 4.538  loss_center: 3.918  loss_offset: 0.06929    time: 1.6110  last_time: 1.5846  data_time: 0.2850  last_data_time: 0.2877   lr: 0.0004973  max_mem: 8671M
[32m[08/12 19:08:58 d2.utils.events]: [39m eta: 3 days, 16:08:27  iter: 1219  total_loss: 7.848  loss_sem_seg: 4.238  loss_center: 3.713  loss_offset: 0.07007    time: 1.6110  last_time: 1.6062  data_time: 0.2946  last_data_time: 0.2421   lr: 0.00049726  max_mem: 8671M
[32m[08/12 19:09:30 d2.utils.events]: [39m eta: 3 days, 16:10:07  iter: 1239  total_loss: 8.197  loss_sem_seg: 4.133  loss_center: 4.054  loss_offset: 0.06309    time: 1.6111  last_time: 1.5666  data_time: 0.2830  last_data_time: 0.2275   lr: 0.00049721  max_mem: 8671M
[32m[08/12 19:10:02 d2.utils.events]: [39m eta: 3 days, 16:06:26  iter: 1259  total_loss: 8.591  loss_sem_seg: 4.432  loss_center: 4.073  loss_offset: 0.06897    time: 1.6104  last_time: 1.6017  data_time: 0.2643  last_data_time: 0.2359   lr: 0.00049717  max_mem: 8671M
[32m[08/12 19:10:35 d2.utils.events]: [39m eta: 3 days, 16:10:48  iter: 1279  total_loss: 8.223  loss_sem_seg: 4.367  loss_center: 3.815  loss_offset: 0.06472    time: 1.6111  last_time: 1.5156  data_time: 0.2912  last_data_time: 0.1858   lr: 0.00049712  max_mem: 8671M
[32m[08/12 19:11:07 d2.utils.events]: [39m eta: 3 days, 16:10:16  iter: 1299  total_loss: 7.473  loss_sem_seg: 4.021  loss_center: 3.373  loss_offset: 0.06198    time: 1.6110  last_time: 1.5137  data_time: 0.2537  last_data_time: 0.2349   lr: 0.00049708  max_mem: 8671M
[32m[08/12 19:11:39 d2.utils.events]: [39m eta: 3 days, 16:05:47  iter: 1319  total_loss: 7.995  loss_sem_seg: 4.244  loss_center: 3.734  loss_offset: 0.06602    time: 1.6111  last_time: 1.6441  data_time: 0.2892  last_data_time: 0.2969   lr: 0.00049703  max_mem: 8671M
[32m[08/12 19:12:12 d2.utils.events]: [39m eta: 3 days, 16:05:51  iter: 1339  total_loss: 8.555  loss_sem_seg: 5.027  loss_center: 3.309  loss_offset: 0.07002    time: 1.6114  last_time: 1.5729  data_time: 0.2888  last_data_time: 0.2564   lr: 0.00049699  max_mem: 8671M
[32m[08/12 19:12:45 d2.utils.events]: [39m eta: 3 days, 16:06:56  iter: 1359  total_loss: 8.013  loss_sem_seg: 4.634  loss_center: 3.359  loss_offset: 0.06223    time: 1.6117  last_time: 1.7557  data_time: 0.3068  last_data_time: 0.2232   lr: 0.00049694  max_mem: 8671M
[32m[08/12 19:13:17 d2.utils.events]: [39m eta: 3 days, 16:11:56  iter: 1379  total_loss: 7.535  loss_sem_seg: 4.025  loss_center: 3.465  loss_offset: 0.06379    time: 1.6116  last_time: 1.6202  data_time: 0.2854  last_data_time: 0.2956   lr: 0.0004969  max_mem: 8671M
[32m[08/12 19:13:49 d2.utils.events]: [39m eta: 3 days, 16:07:59  iter: 1399  total_loss: 7.618  loss_sem_seg: 4.234  loss_center: 3.338  loss_offset: 0.05607    time: 1.6113  last_time: 1.5888  data_time: 0.2787  last_data_time: 0.3518   lr: 0.00049685  max_mem: 8671M
[32m[08/12 19:14:21 d2.utils.events]: [39m eta: 3 days, 16:08:26  iter: 1419  total_loss: 7.16  loss_sem_seg: 3.854  loss_center: 3.122  loss_offset: 0.06452    time: 1.6116  last_time: 1.6113  data_time: 0.2806  last_data_time: 0.2411   lr: 0.00049681  max_mem: 8671M
[32m[08/12 19:14:53 d2.utils.events]: [39m eta: 3 days, 16:08:27  iter: 1439  total_loss: 6.885  loss_sem_seg: 3.754  loss_center: 3.102  loss_offset: 0.05624    time: 1.6115  last_time: 1.5395  data_time: 0.2926  last_data_time: 0.2366   lr: 0.00049676  max_mem: 8671M
[32m[08/12 19:15:25 d2.utils.events]: [39m eta: 3 days, 16:05:26  iter: 1459  total_loss: 7.036  loss_sem_seg: 3.732  loss_center: 3.132  loss_offset: 0.05804    time: 1.6114  last_time: 1.4604  data_time: 0.2728  last_data_time: 0.2435   lr: 0.00049672  max_mem: 8671M
[32m[08/12 19:15:57 d2.utils.events]: [39m eta: 3 days, 16:10:17  iter: 1479  total_loss: 6.712  loss_sem_seg: 3.78  loss_center: 3  loss_offset: 0.05982    time: 1.6113  last_time: 1.4603  data_time: 0.2701  last_data_time: 0.2134   lr: 0.00049667  max_mem: 8671M
[32m[08/12 19:16:30 d2.utils.events]: [39m eta: 3 days, 16:12:50  iter: 1499  total_loss: 7.147  loss_sem_seg: 3.966  loss_center: 3.008  loss_offset: 0.06213    time: 1.6117  last_time: 1.5308  data_time: 0.3169  last_data_time: 0.2770   lr: 0.00049663  max_mem: 8671M
[32m[08/12 19:17:02 d2.utils.events]: [39m eta: 3 days, 16:09:13  iter: 1519  total_loss: 6.371  loss_sem_seg: 3.516  loss_center: 2.887  loss_offset: 0.05979    time: 1.6112  last_time: 1.6793  data_time: 0.2576  last_data_time: 0.2271   lr: 0.00049658  max_mem: 8671M
[32m[08/12 19:17:34 d2.utils.events]: [39m eta: 3 days, 16:07:41  iter: 1539  total_loss: 6.758  loss_sem_seg: 3.632  loss_center: 2.822  loss_offset: 0.05634    time: 1.6111  last_time: 1.5140  data_time: 0.2697  last_data_time: 0.2407   lr: 0.00049654  max_mem: 8671M
[32m[08/12 19:18:06 d2.utils.events]: [39m eta: 3 days, 16:10:46  iter: 1559  total_loss: 6.394  loss_sem_seg: 3.476  loss_center: 2.873  loss_offset: 0.05375    time: 1.6113  last_time: 1.7498  data_time: 0.2849  last_data_time: 0.3184   lr: 0.00049649  max_mem: 8671M
[32m[08/12 19:18:39 d2.utils.events]: [39m eta: 3 days, 16:06:37  iter: 1579  total_loss: 6.56  loss_sem_seg: 3.637  loss_center: 3.027  loss_offset: 0.05478    time: 1.6116  last_time: 1.5376  data_time: 0.2808  last_data_time: 0.2277   lr: 0.00049645  max_mem: 8671M
[32m[08/12 19:19:12 d2.utils.events]: [39m eta: 3 days, 16:08:39  iter: 1599  total_loss: 6.75  loss_sem_seg: 3.54  loss_center: 2.967  loss_offset: 0.05292    time: 1.6117  last_time: 1.6604  data_time: 0.2894  last_data_time: 0.3509   lr: 0.0004964  max_mem: 8671M
[32m[08/12 19:19:44 d2.utils.events]: [39m eta: 3 days, 16:14:37  iter: 1619  total_loss: 6.742  loss_sem_seg: 3.47  loss_center: 3.12  loss_offset: 0.05467    time: 1.6119  last_time: 1.6651  data_time: 0.2825  last_data_time: 0.2576   lr: 0.00049636  max_mem: 8671M
[32m[08/12 19:20:16 d2.utils.events]: [39m eta: 3 days, 16:12:20  iter: 1639  total_loss: 6.687  loss_sem_seg: 3.641  loss_center: 2.986  loss_offset: 0.05445    time: 1.6117  last_time: 1.5909  data_time: 0.2732  last_data_time: 0.3177   lr: 0.00049631  max_mem: 8671M
[32m[08/12 19:20:48 d2.utils.events]: [39m eta: 3 days, 16:11:05  iter: 1659  total_loss: 6.678  loss_sem_seg: 3.525  loss_center: 3.01  loss_offset: 0.05791    time: 1.6117  last_time: 1.5757  data_time: 0.2636  last_data_time: 0.2036   lr: 0.00049627  max_mem: 8671M
[32m[08/12 19:21:21 d2.utils.events]: [39m eta: 3 days, 16:12:13  iter: 1679  total_loss: 6.159  loss_sem_seg: 3.339  loss_center: 2.901  loss_offset: 0.05442    time: 1.6118  last_time: 1.7920  data_time: 0.3133  last_data_time: 0.3876   lr: 0.00049622  max_mem: 8671M
[32m[08/12 19:21:52 d2.utils.events]: [39m eta: 3 days, 16:12:59  iter: 1699  total_loss: 6.108  loss_sem_seg: 3.358  loss_center: 2.864  loss_offset: 0.05426    time: 1.6114  last_time: 1.4852  data_time: 0.2687  last_data_time: 0.1998   lr: 0.00049618  max_mem: 8671M
[32m[08/12 19:22:25 d2.utils.events]: [39m eta: 3 days, 16:11:09  iter: 1719  total_loss: 6.272  loss_sem_seg: 3.455  loss_center: 2.771  loss_offset: 0.05792    time: 1.6117  last_time: 1.6175  data_time: 0.2889  last_data_time: 0.3744   lr: 0.00049613  max_mem: 8671M
[32m[08/12 19:22:58 d2.utils.events]: [39m eta: 3 days, 16:15:48  iter: 1739  total_loss: 6.162  loss_sem_seg: 3.375  loss_center: 2.917  loss_offset: 0.05493    time: 1.6120  last_time: 1.6327  data_time: 0.2937  last_data_time: 0.3261   lr: 0.00049609  max_mem: 8671M
[32m[08/12 19:23:29 d2.utils.events]: [39m eta: 3 days, 16:13:30  iter: 1759  total_loss: 6.018  loss_sem_seg: 3.37  loss_center: 2.589  loss_offset: 0.0516    time: 1.6115  last_time: 1.5754  data_time: 0.2653  last_data_time: 0.2790   lr: 0.00049604  max_mem: 8671M
[32m[08/12 19:24:02 d2.utils.events]: [39m eta: 3 days, 16:10:51  iter: 1779  total_loss: 6.138  loss_sem_seg: 3.306  loss_center: 2.734  loss_offset: 0.05158    time: 1.6118  last_time: 1.5735  data_time: 0.3100  last_data_time: 0.2543   lr: 0.000496  max_mem: 8671M
[32m[08/12 19:24:35 d2.utils.events]: [39m eta: 3 days, 16:10:19  iter: 1799  total_loss: 5.941  loss_sem_seg: 3.256  loss_center: 2.676  loss_offset: 0.05304    time: 1.6121  last_time: 1.6479  data_time: 0.2839  last_data_time: 0.2603   lr: 0.00049595  max_mem: 8671M
[32m[08/12 19:25:06 d2.utils.events]: [39m eta: 3 days, 16:08:31  iter: 1819  total_loss: 5.8  loss_sem_seg: 3.263  loss_center: 2.476  loss_offset: 0.05108    time: 1.6115  last_time: 1.6966  data_time: 0.2680  last_data_time: 0.4817   lr: 0.00049591  max_mem: 8671M
[32m[08/12 19:25:38 d2.utils.events]: [39m eta: 3 days, 16:10:32  iter: 1839  total_loss: 5.872  loss_sem_seg: 3.414  loss_center: 2.475  loss_offset: 0.04857    time: 1.6115  last_time: 1.6946  data_time: 0.2895  last_data_time: 0.2645   lr: 0.00049586  max_mem: 8671M
[32m[08/12 19:26:11 d2.utils.events]: [39m eta: 3 days, 16:07:27  iter: 1859  total_loss: 5.79  loss_sem_seg: 3.336  loss_center: 2.333  loss_offset: 0.05095    time: 1.6118  last_time: 1.7420  data_time: 0.2806  last_data_time: 0.3361   lr: 0.00049582  max_mem: 8671M
[32m[08/12 19:26:43 d2.utils.events]: [39m eta: 3 days, 16:08:11  iter: 1879  total_loss: 5.307  loss_sem_seg: 3.175  loss_center: 2.382  loss_offset: 0.04771    time: 1.6115  last_time: 1.5967  data_time: 0.2565  last_data_time: 0.2350   lr: 0.00049577  max_mem: 8671M
[32m[08/12 19:27:14 d2.utils.events]: [39m eta: 3 days, 16:05:50  iter: 1899  total_loss: 5.832  loss_sem_seg: 3.262  loss_center: 2.437  loss_offset: 0.0476    time: 1.6112  last_time: 1.4777  data_time: 0.2733  last_data_time: 0.2210   lr: 0.00049573  max_mem: 8671M
[31m[4m[5mERROR[39m[24m[25m [32m[08/12 19:27:14 d2.engine.train_loop]: [39mException during training:
Traceback (most recent call last):
  File "/home/liwa/project/OneFormer/detectron2/detectron2/engine/train_loop.py", line 156, in train
    self.after_step()
  File "/home/liwa/project/OneFormer/detectron2/detectron2/engine/train_loop.py", line 190, in after_step
    h.after_step()
  File "/home/liwa/project/OneFormer/detectron2/detectron2/engine/hooks.py", line 181, in after_step
    writer.write()
  File "/home/liwa/project/OneFormer/detectron2/detectron2/utils/events.py", line 131, in write
    self._file_handle.flush()
OSError: [Errno 28] No space left on device
[32m[08/12 19:27:14 d2.engine.hooks]: [39mOverall training speed: 1897 iterations in 0:50:58 (1.6121 s / it)
[32m[08/12 19:27:14 d2.engine.hooks]: [39mTotal training time: 0:50:59 (0:00:00 on hooks)
[32m[08/12 19:27:14 d2.utils.events]: [39m eta: 3 days, 16:05:50  iter: 1899  total_loss: 5.832  loss_sem_seg: 3.262  loss_center: 2.437  loss_offset: 0.0476    time: 1.6112  last_time: 1.4777  data_time: 0.2733  last_data_time: 0.2210   lr: 0.00049573  max_mem: 8671M
--- Logging error ---
Traceback (most recent call last):
  File "/home/liwa/project/OneFormer/detectron2/detectron2/engine/train_loop.py", line 156, in train
    self.after_step()
  File "/home/liwa/project/OneFormer/detectron2/detectron2/engine/train_loop.py", line 190, in after_s