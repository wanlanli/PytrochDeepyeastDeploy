[32m[07/29 16:25:16 d2.engine.defaults]: [39mModel:
PanopticDeepLab(
  (backbone): ResNet(
    (stem): DeepLabStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (conv2): Conv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (conv3): Conv2d(
        64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): PanopticDeepLabSemSegHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False
            (norm): SyncBatchNorm(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            288, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
            (norm): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(20, 20), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (head): DepthwiseSeparableConv2d(
      (depthwise): Conv2d(
        256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256, bias=False
        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (pointwise): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (predictor): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))
    (loss): DeepLabCE(
      (criterion): CrossEntropyLoss()
    )
  )
  (ins_embed_head): PanopticDeepLabInsEmbedHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            160, 160, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=160, bias=False
            (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
            (norm): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(20, 20), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (center_head): Sequential(
      (0): Conv2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): Conv2d(
        128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (center_predictor): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))
    (offset_head): DepthwiseSeparableConv2d(
      (depthwise): Conv2d(
        128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128, bias=False
        (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (pointwise): Conv2d(
        128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (offset_predictor): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))
    (center_loss): MSELoss()
    (offset_loss): L1Loss()
  )
)
[32m[07/29 16:25:16 d2.projects.panoptic_deeplab.dataset_mapper]: [39mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(160, 192, 224, 256, 288, 320, 352, 384, 416, 448, 480), max_size=640, sample_style='choice'), RandomCrop(crop_type='absolute', crop_size=[320, 320]), RandomFlip()]
[32m[07/29 16:25:17 d2.data.build]: [39mRemoved 0 images with no usable annotations. 100 images left.
[32m[07/29 16:25:17 d2.data.build]: [39mDistribution of instances among all 8 categories:
[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |
[36m|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
[36m|   cell1    | 5175         |   cell2    | 355          |   cell3    | 434          |
[36m|   tetrad   | 1584         |   cell5    | 30           |   cell6    | 21           |
[36m|   cell7    | 4            |   cell8    | 1            |            |              |
[36m|   total    | 7604         |            |              |            |              |
[32m[07/29 16:25:17 d2.data.build]: [39mUsing training sampler TrainingSampler
[32m[07/29 16:25:17 d2.data.common]: [39mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[32m[07/29 16:25:17 d2.data.common]: [39mSerializing 100 elements to byte tensors and concatenating them all ...
[32m[07/29 16:25:17 d2.data.common]: [39mSerialized dataset takes 7.79 MiB
[32m[07/29 16:25:17 d2.data.build]: [39mMaking batched data loader with batch_size=16
[32m[07/29 16:25:17 d2.checkpoint.detection_checkpoint]: [39m[DetectionCheckpointer] Loading from /home/liwa/project/OneFormer/detectron2/projects/Panoptic-DeepLab/output_0727/model_final.pth ...
[32m[07/29 16:25:17 fvcore.common.checkpoint]: [39m[Checkpointer] Loading from /home/liwa/project/OneFormer/detectron2/projects/Panoptic-DeepLab/output_0727/model_final.pth ...
[31m[5mWARNING[39m[25m [32m[07/29 16:25:17 fvcore.common.checkpoint]: [39mSkip loading parameter 'sem_seg_head.predictor.weight' to the model due to incompatible shapes: (133, 256, 1, 1) in the checkpoint but (8, 256, 1, 1) in the model! You might want to double check if this is expected.
[31m[5mWARNING[39m[25m [32m[07/29 16:25:17 fvcore.common.checkpoint]: [39mSkip loading parameter 'sem_seg_head.predictor.bias' to the model due to incompatible shapes: (133,) in the checkpoint but (8,) in the model! You might want to double check if this is expected.
[31m[5mWARNING[39m[25m [32m[07/29 16:25:17 fvcore.common.checkpoint]: [39mSome model parameters or buffers are not found in the checkpoint:
[34msem_seg_head.predictor.{bias, weight}
[32m[07/29 16:25:17 d2.engine.train_loop]: [39mStarting training from iteration 0
[32m[07/29 16:26:04 d2.utils.events]: [39m eta: 3:15:15  iter: 19  total_loss: 2.027  loss_sem_seg: 1.98  loss_center: 0.03083  loss_offset: 0.01486    time: 1.1789  last_time: 1.3309  data_time: 1.4117  last_data_time: 0.3764   lr: 9.9734e-06  max_mem: 7171M
[32m[07/29 16:26:27 d2.utils.events]: [39m eta: 3:13:28  iter: 39  total_loss: 1.958  loss_sem_seg: 1.915  loss_center: 0.02953  loss_offset: 0.01489    time: 1.1692  last_time: 1.1023  data_time: 0.2855  last_data_time: 0.2676   lr: 1.991e-05  max_mem: 7171M
[32m[07/29 16:26:51 d2.utils.events]: [39m eta: 3:13:22  iter: 59  total_loss: 1.86  loss_sem_seg: 1.812  loss_center: 0.03042  loss_offset: 0.01482    time: 1.1763  last_time: 1.1681  data_time: 0.3080  last_data_time: 0.3012   lr: 2.9811e-05  max_mem: 7171M
[32m[07/29 16:27:15 d2.utils.events]: [39m eta: 3:14:09  iter: 79  total_loss: 1.663  loss_sem_seg: 1.619  loss_center: 0.03131  loss_offset: 0.01486    time: 1.1851  last_time: 1.2621  data_time: 0.3083  last_data_time: 0.4218   lr: 3.9676e-05  max_mem: 7171M
[32m[07/29 16:27:39 d2.utils.events]: [39m eta: 3:13:18  iter: 99  total_loss: 1.385  loss_sem_seg: 1.337  loss_center: 0.03188  loss_offset: 0.01506    time: 1.1876  last_time: 1.2555  data_time: 0.3073  last_data_time: 0.4173   lr: 4.9505e-05  max_mem: 7171M
[32m[07/29 16:28:03 d2.utils.events]: [39m eta: 3:13:22  iter: 119  total_loss: 1.165  loss_sem_seg: 1.117  loss_center: 0.03179  loss_offset: 0.01522    time: 1.1915  last_time: 1.1528  data_time: 0.3057  last_data_time: 0.2888   lr: 5.9298e-05  max_mem: 7171M
[32m[07/29 16:28:27 d2.utils.events]: [39m eta: 3:12:32  iter: 139  total_loss: 0.9343  loss_sem_seg: 0.8876  loss_center: 0.03107  loss_offset: 0.01517    time: 1.1918  last_time: 1.1327  data_time: 0.2966  last_data_time: 0.2482   lr: 6.9055e-05  max_mem: 7172M
[32m[07/29 16:28:51 d2.utils.events]: [39m eta: 3:12:26  iter: 159  total_loss: 0.7778  loss_sem_seg: 0.7294  loss_center: 0.03408  loss_offset: 0.01517    time: 1.1918  last_time: 1.1895  data_time: 0.2705  last_data_time: 0.2793   lr: 7.8776e-05  max_mem: 7172M
[32m[07/29 16:29:15 d2.utils.events]: [39m eta: 3:12:45  iter: 179  total_loss: 0.6185  loss_sem_seg: 0.5692  loss_center: 0.03387  loss_offset: 0.01525    time: 1.1927  last_time: 1.0726  data_time: 0.2726  last_data_time: 0.2287   lr: 8.8461e-05  max_mem: 7172M
[32m[07/29 16:29:39 d2.utils.events]: [39m eta: 3:12:36  iter: 199  total_loss: 0.5141  loss_sem_seg: 0.4664  loss_center: 0.03207  loss_offset: 0.0154    time: 1.1931  last_time: 1.1430  data_time: 0.2682  last_data_time: 0.2495   lr: 9.8109e-05  max_mem: 7172M
[32m[07/29 16:30:03 d2.utils.events]: [39m eta: 3:13:01  iter: 219  total_loss: 0.4307  loss_sem_seg: 0.383  loss_center: 0.03299  loss_offset: 0.01519    time: 1.1962  last_time: 1.1835  data_time: 0.2803  last_data_time: 0.2482   lr: 0.00010772  max_mem: 7172M
[32m[07/29 16:30:27 d2.utils.events]: [39m eta: 3:12:47  iter: 239  total_loss: 0.3451  loss_sem_seg: 0.2936  loss_center: 0.03248  loss_offset: 0.01528    time: 1.1976  last_time: 1.2375  data_time: 0.2694  last_data_time: 0.2322   lr: 0.0001173  max_mem: 7172M
[32m[07/29 16:30:51 d2.utils.events]: [39m eta: 3:12:23  iter: 259  total_loss: 0.2922  loss_sem_seg: 0.2394  loss_center: 0.03303  loss_offset: 0.0153    time: 1.1978  last_time: 1.1126  data_time: 0.2712  last_data_time: 0.2593   lr: 0.00012684  max_mem: 7172M
[32m[07/29 16:31:16 d2.utils.events]: [39m eta: 3:11:57  iter: 279  total_loss: 0.2695  loss_sem_seg: 0.2225  loss_center: 0.03243  loss_offset: 0.01528    time: 1.1982  last_time: 1.2491  data_time: 0.2954  last_data_time: 0.4358   lr: 0.00013634  max_mem: 7172M
[32m[07/29 16:31:40 d2.utils.events]: [39m eta: 3:11:44  iter: 299  total_loss: 0.2234  loss_sem_seg: 0.173  loss_center: 0.03175  loss_offset: 0.01512    time: 1.1996  last_time: 1.2520  data_time: 0.2867  last_data_time: 0.3928   lr: 0.00014581  max_mem: 7172M
[32m[07/29 16:32:04 d2.utils.events]: [39m eta: 3:11:27  iter: 319  total_loss: 0.1837  loss_sem_seg: 0.1391  loss_center: 0.03301  loss_offset: 0.01534    time: 1.2007  last_time: 1.1421  data_time: 0.2951  last_data_time: 0.2513   lr: 0.00015524  max_mem: 7172M
[32m[07/29 16:32:28 d2.utils.events]: [39m eta: 3:11:21  iter: 339  total_loss: 0.1706  loss_sem_seg: 0.1259  loss_center: 0.03217  loss_offset: 0.01502    time: 1.2013  last_time: 1.2786  data_time: 0.2979  last_data_time: 0.2539   lr: 0.00016464  max_mem: 7172M
[32m[07/29 16:32:53 d2.utils.events]: [39m eta: 3:11:04  iter: 359  total_loss: 0.1577  loss_sem_seg: 0.107  loss_center: 0.03241  loss_offset: 0.01519    time: 1.2028  last_time: 1.2983  data_time: 0.2804  last_data_time: 0.4484   lr: 0.000174  max_mem: 7172M
[32m[07/29 16:33:18 d2.utils.events]: [39m eta: 3:10:45  iter: 379  total_loss: 0.1395  loss_sem_seg: 0.09206  loss_center: 0.03271  loss_offset: 0.01521    time: 1.2041  last_time: 1.4108  data_time: 0.2838  last_data_time: 0.4166   lr: 0.00018332  max_mem: 7172M
[32m[07/29 16:33:42 d2.utils.events]: [39m eta: 3:10:52  iter: 399  total_loss: 0.1307  loss_sem_seg: 0.08407  loss_center: 0.03302  loss_offset: 0.01523    time: 1.2051  last_time: 1.3600  data_time: 0.2972  last_data_time: 0.5059   lr: 0.00019261  max_mem: 7172M
[32m[07/29 16:34:07 d2.utils.events]: [39m eta: 3:11:06  iter: 419  total_loss: 0.1241  loss_sem_seg: 0.07705  loss_center: 0.03237  loss_offset: 0.01528    time: 1.2068  last_time: 1.3335  data_time: 0.3123  last_data_time: 0.2971   lr: 0.00020186  max_mem: 7172M
[32m[07/29 16:34:31 d2.utils.events]: [39m eta: 3:10:55  iter: 439  total_loss: 0.1223  loss_sem_seg: 0.07384  loss_center: 0.03234  loss_offset: 0.01532    time: 1.2069  last_time: 1.2007  data_time: 0.2885  last_data_time: 0.2431   lr: 0.00021108  max_mem: 7172M
[32m[07/29 16:34:55 d2.utils.events]: [39m eta: 3:10:44  iter: 459  total_loss: 0.1176  loss_sem_seg: 0.06767  loss_center: 0.03393  loss_offset: 0.0152    time: 1.2072  last_time: 1.2067  data_time: 0.2963  last_data_time: 0.3580   lr: 0.00022026  max_mem: 7172M
[32m[07/29 16:35:19 d2.utils.events]: [39m eta: 3:10:20  iter: 479  total_loss: 0.1159  loss_sem_seg: 0.0657  loss_center: 0.0324  loss_offset: 0.01519    time: 1.2069  last_time: 1.0457  data_time: 0.2664  last_data_time: 0.1990   lr: 0.0002294  max_mem: 7172M
[32m[07/29 16:35:44 d2.utils.events]: [39m eta: 3:09:56  iter: 499  total_loss: 0.1141  loss_sem_seg: 0.06173  loss_center: 0.03595  loss_offset: 0.01537    time: 1.2069  last_time: 1.2075  data_time: 0.2800  last_data_time: 0.3611   lr: 0.00023851  max_mem: 7172M
[32m[07/29 16:36:08 d2.utils.events]: [39m eta: 3:09:32  iter: 519  total_loss: 0.11  loss_sem_seg: 0.06063  loss_center: 0.0345  loss_offset: 0.01529    time: 1.2072  last_time: 1.2168  data_time: 0.2861  last_data_time: 0.3348   lr: 0.00024758  max_mem: 7172M
[32m[07/29 16:36:32 d2.utils.events]: [39m eta: 3:09:16  iter: 539  total_loss: 0.1049  loss_sem_seg: 0.05714  loss_center: 0.03303  loss_offset: 0.01515    time: 1.2073  last_time: 1.2194  data_time: 0.2942  last_data_time: 0.4057   lr: 0.00025661  max_mem: 7172M
[32m[07/29 16:36:56 d2.utils.events]: [39m eta: 3:08:52  iter: 559  total_loss: 0.1044  loss_sem_seg: 0.05659  loss_center: 0.03368  loss_offset: 0.01535    time: 1.2075  last_time: 1.1476  data_time: 0.2819  last_data_time: 0.3025   lr: 0.00026561  max_mem: 7172M
[32m[07/29 16:37:21 d2.utils.events]: [39m eta: 3:08:29  iter: 579  total_loss: 0.102  loss_sem_seg: 0.05408  loss_center: 0.03265  loss_offset: 0.01529    time: 1.2078  last_time: 1.1049  data_time: 0.2962  last_data_time: 0.2391   lr: 0.00027457  max_mem: 7172M
[32m[07/29 16:37:45 d2.utils.events]: [39m eta: 3:08:05  iter: 599  total_loss: 0.1005  loss_sem_seg: 0.05146  loss_center: 0.0327  loss_offset: 0.01514    time: 1.2080  last_time: 1.2533  data_time: 0.2774  last_data_time: 0.2710   lr: 0.00028349  max_mem: 7172M
[32m[07/29 16:38:09 d2.utils.events]: [39m eta: 3:07:46  iter: 619  total_loss: 0.0976  loss_sem_seg: 0.05116  loss_center: 0.03145  loss_offset: 0.0153    time: 1.2079  last_time: 1.2932  data_time: 0.3002  last_data_time: 0.2803   lr: 0.00029238  max_mem: 7172M
[32m[07/29 16:38:33 d2.utils.events]: [39m eta: 3:07:16  iter: 639  total_loss: 0.09757  loss_sem_seg: 0.05038  loss_center: 0.03277  loss_offset: 0.01531    time: 1.2073  last_time: 1.1943  data_time: 0.2886  last_data_time: 0.3062   lr: 0.00030124  max_mem: 7172M
[32m[07/29 16:38:57 d2.utils.events]: [39m eta: 3:06:53  iter: 659  total_loss: 0.0965  loss_sem_seg: 0.04776  loss_center: 0.03391  loss_offset: 0.01521    time: 1.2073  last_time: 1.2165  data_time: 0.2876  last_data_time: 0.3495   lr: 0.00031005  max_mem: 7172M
[32m[07/29 16:39:21 d2.utils.events]: [39m eta: 3:06:20  iter: 679  total_loss: 0.09477  loss_sem_seg: 0.04655  loss_center: 0.03383  loss_offset: 0.01521    time: 1.2071  last_time: 1.2740  data_time: 0.3068  last_data_time: 0.3203   lr: 0.00031883  max_mem: 7172M
[32m[07/29 16:39:45 d2.utils.events]: [39m eta: 3:05:49  iter: 699  total_loss: 0.09822  loss_sem_seg: 0.04653  loss_center: 0.03596  loss_offset: 0.01538    time: 1.2071  last_time: 1.1147  data_time: 0.2836  last_data_time: 0.2322   lr: 0.00032758  max_mem: 7172M
[32m[07/29 16:40:09 d2.utils.events]: [39m eta: 3:05:12  iter: 719  total_loss: 0.1146  loss_sem_seg: 0.04707  loss_center: 0.05128  loss_offset: 0.01635    time: 1.2072  last_time: 1.1957  data_time: 0.3014  last_data_time: 0.2605   lr: 0.00033628  max_mem: 7172M
[32m[07/29 16:40:34 d2.utils.events]: [39m eta: 3:04:56  iter: 739  total_loss: 0.1027  loss_sem_seg: 0.04642  loss_center: 0.04203  loss_offset: 0.01602    time: 1.2073  last_time: 1.0989  data_time: 0.3039  last_data_time: 0.2231   lr: 0.00034495  max_mem: 7172M
[32m[07/29 16:40:58 d2.utils.events]: [39m eta: 3:04:38  iter: 759  total_loss: 0.1007  loss_sem_seg: 0.04549  loss_center: 0.03894  loss_offset: 0.0157    time: 1.2071  last_time: 1.2904  data_time: 0.2960  last_data_time: 0.2941   lr: 0.00035359  max_mem: 7172M
[32m[07/29 16:41:22 d2.utils.events]: [39m eta: 3:04:20  iter: 779  total_loss: 0.09544  loss_sem_seg: 0.04291  loss_center: 0.03528  loss_offset: 0.01558    time: 1.2075  last_time: 1.1497  data_time: 0.2810  last_data_time: 0.2708   lr: 0.00036219  max_mem: 7172M
[32m[07/29 16:41:46 d2.utils.events]: [39m eta: 3:03:51  iter: 799  total_loss: 0.09241  loss_sem_seg: 0.04162  loss_center: 0.03693  loss_offset: 0.01557    time: 1.2075  last_time: 1.3372  data_time: 0.2830  last_data_time: 0.3726   lr: 0.00037075  max_mem: 7172M
[32m[07/29 16:42:10 d2.utils.events]: [39m eta: 3:03:28  iter: 819  total_loss: 0.09525  loss_sem_seg: 0.04152  loss_center: 0.03613  loss_offset: 0.01565    time: 1.2075  last_time: 1.2783  data_time: 0.2905  last_data_time: 0.2793   lr: 0.00037927  max_mem: 7172M
[32m[07/29 16:42:35 d2.utils.events]: [39m eta: 3:03:08  iter: 839  total_loss: 0.09303  loss_sem_seg: 0.04171  loss_center: 0.03665  loss_offset: 0.01538    time: 1.2076  last_time: 1.3048  data_time: 0.2956  last_data_time: 0.4197   lr: 0.00038776  max_mem: 7172M
[32m[07/29 16:42:59 d2.utils.events]: [39m eta: 3:02:54  iter: 859  total_loss: 0.09178  loss_sem_seg: 0.04111  loss_center: 0.03514  loss_offset: 0.01544    time: 1.2080  last_time: 1.1568  data_time: 0.2815  last_data_time: 0.3485   lr: 0.00039621  max_mem: 7172M
[32m[07/29 16:43:23 d2.utils.events]: [39m eta: 3:02:30  iter: 879  total_loss: 0.08996  loss_sem_seg: 0.03999  loss_center: 0.03446  loss_offset: 0.01545    time: 1.2079  last_time: 1.3474  data_time: 0.2868  last_data_time: 0.2839   lr: 0.00040463  max_mem: 7172M
[32m[07/29 16:43:47 d2.utils.events]: [39m eta: 3:02:05  iter: 899  total_loss: 0.09033  loss_sem_seg: 0.03945  loss_center: 0.03525  loss_offset: 0.01549    time: 1.2077  last_time: 1.2461  data_time: 0.2983  last_data_time: 0.2930   lr: 0.00041301  max_mem: 7172M
[32m[07/29 16:44:11 d2.utils.events]: [39m eta: 3:01:41  iter: 919  total_loss: 0.09021  loss_sem_seg: 0.0376  loss_center: 0.03494  loss_offset: 0.01561    time: 1.2077  last_time: 1.3058  data_time: 0.2804  last_data_time: 0.2500   lr: 0.00042135  max_mem: 7172M
[32m[07/29 16:44:36 d2.utils.events]: [39m eta: 3:01:18  iter: 939  total_loss: 0.09339  loss_sem_seg: 0.03913  loss_center: 0.03998  loss_offset: 0.01593    time: 1.2079  last_time: 1.2814  data_time: 0.2977  last_data_time: 0.2458   lr: 0.00042966  max_mem: 7172M
[32m[07/29 16:45:00 d2.utils.events]: [39m eta: 3:01:05  iter: 959  total_loss: 0.1087  loss_sem_seg: 0.03967  loss_center: 0.05154  loss_offset: 0.01632    time: 1.2081  last_time: 1.1071  data_time: 0.2932  last_data_time: 0.2528   lr: 0.00043793  max_mem: 7172M
[32m[07/29 16:45:25 d2.utils.events]: [39m eta: 3:00:43  iter: 979  total_loss: 0.1094  loss_sem_seg: 0.03704  loss_center: 0.05188  loss_offset: 0.0168    time: 1.2087  last_time: 1.1156  data_time: 0.3005  last_data_time: 0.2738   lr: 0.00044616  max_mem: 7172M
[32m[07/29 16:45:49 fvcore.common.checkpoint]: [39mSaving checkpoint to ./output/model_0000999.pth
[32m[07/29 16:45:49 d2.utils.events]: [39m eta: 3:00:17  iter: 999  total_loss: 0.1047  loss_sem_seg: 0.03905  loss_center: 0.04706  loss_offset: 0.01676    time: 1.2084  last_time: 1.1647  data_time: 0.2979  last_data_time: 0.2639   lr: 0.00045436  max_mem: 7172M
[32m[07/29 16:46:13 d2.utils.events]: [39m eta: 2:59:59  iter: 1019  total_loss: 0.1011  loss_sem_seg: 0.03729  loss_center: 0.04611  loss_offset: 0.01634    time: 1.2083  last_time: 1.2819  data_time: 0.2806  last_data_time: 0.2531   lr: 0.0004539  max_mem: 7172M
