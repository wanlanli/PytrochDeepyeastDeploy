[32m[08/07 13:10:36 d2.engine.defaults]: [39mModel:
PanopticDeepLab(
  (backbone): ResNet(
    (stem): DeepLabStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (conv2): Conv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (conv3): Conv2d(
        64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): PanopticDeepLabSemSegHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): Sequential(
          (0): Conv2d(
            288, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): Sequential(
          (0): Conv2d(
            320, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): Conv2d(
              2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False
              (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): Conv2d(
              2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False
              (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): Conv2d(
              2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False
              (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(32, 32), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (head): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (predictor): Conv2d(256, 9, kernel_size=(1, 1), stride=(1, 1))
    (loss): DeepLabCE(
      (criterion): CrossEntropyLoss()
    )
  )
  (ins_embed_head): PanopticDeepLabInsEmbedHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): Sequential(
          (0): Conv2d(
            160, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): Sequential(
          (0): Conv2d(
            320, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): Conv2d(
              2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False
              (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): Conv2d(
              2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False
              (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): Conv2d(
              2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False
              (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(32, 32), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (center_head): Sequential(
      (0): Conv2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): Conv2d(
        128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (center_predictor): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))
    (offset_head): Sequential(
      (0): Conv2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): Conv2d(
        128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (offset_predictor): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))
    (center_loss): MSELoss()
    (offset_loss): L1Loss()
  )
)
[32m[08/07 13:10:36 d2.projects.panoptic_deeplab.dataset_mapper]: [39mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(256, 307, 358, 409, 460, 512, 563, 614, 665, 716, 768), max_size=1024, sample_style='choice'), RandomCrop(crop_type='absolute', crop_size=[512, 512]), RandomFlip(), RandomBrightness(intensity_min=0.5, intensity_max=1.5), RandomContrast(intensity_min=0.5, intensity_max=1.5)]
[32m[08/07 13:10:36 d2.data.build]: [39mUsing training sampler TrainingSampler
[32m[08/07 13:10:36 d2.data.common]: [39mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[32m[08/07 13:10:36 d2.data.common]: [39mSerializing 100 elements to byte tensors and concatenating them all ...
[32m[08/07 13:10:36 d2.data.common]: [39mSerialized dataset takes 0.35 MiB
[32m[08/07 13:10:36 d2.data.build]: [39mMaking batched data loader with batch_size=8
[32m[08/07 13:10:36 d2.checkpoint.detection_checkpoint]: [39m[DetectionCheckpointer] Loading from detectron2://DeepLab/R-52.pkl ...
[32m[08/07 13:10:36 fvcore.common.checkpoint]: [39m[Checkpointer] Loading from /home/liwa/.torch/iopath_cache/detectron2/DeepLab/R-52.pkl ...
[32m[08/07 13:10:37 fvcore.common.checkpoint]: [39mReading a file from 'torchvision'
[32m[08/07 13:10:37 d2.checkpoint.c2_model_loading]: [39mFollowing weights matched with submodule backbone - Total num: 55
[31m[5mWARNING[39m[25m [32m[08/07 13:10:37 fvcore.common.checkpoint]: [39mSome model parameters or buffers are not found in the checkpoint:
[34mins_embed_head.center_head.0.norm.{bias, running_mean, running_var, weight}
[34mins_embed_head.center_head.0.weight
[34mins_embed_head.center_head.1.norm.{bias, running_mean, running_var, weight}
[34mins_embed_head.center_head.1.weight
[34mins_embed_head.center_predictor.{bias, weight}
[34mins_embed_head.decoder.res2.fuse_conv.0.norm.{bias, running_mean, running_var, weight}
[34mins_embed_head.decoder.res2.fuse_conv.0.weight
[34mins_embed_head.decoder.res2.fuse_conv.1.norm.{bias, running_mean, running_var, weight}
[34mins_embed_head.decoder.res2.fuse_conv.1.weight
[34mins_embed_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}
[34mins_embed_head.decoder.res2.project_conv.weight
[34mins_embed_head.decoder.res3.fuse_conv.0.norm.{bias, running_mean, running_var, weight}
[34mins_embed_head.decoder.res3.fuse_conv.0.weight
[34mins_embed_head.decoder.res3.fuse_conv.1.norm.{bias, running_mean, running_var, weight}
[34mins_embed_head.decoder.res3.fuse_conv.1.weight
[34mins_embed_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}
[34mins_embed_head.decoder.res3.project_conv.weight
[34mins_embed_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}
[34mins_embed_head.decoder.res5.project_conv.convs.0.weight
[34mins_embed_head.decoder.res5.project_conv.convs.1.norm.{bias, running_mean, running_var, weight}
[34mins_embed_head.decoder.res5.project_conv.convs.1.weight
[34mins_embed_head.decoder.res5.project_conv.convs.2.norm.{bias, running_mean, running_var, weight}
[34mins_embed_head.decoder.res5.project_conv.convs.2.weight
[34mins_embed_head.decoder.res5.project_conv.convs.3.norm.{bias, running_mean, running_var, weight}
[34mins_embed_head.decoder.res5.project_conv.convs.3.weight
[34mins_embed_head.decoder.res5.project_conv.convs.4.1.{bias, weight}
[34mins_embed_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}
[34mins_embed_head.decoder.res5.project_conv.project.weight
[34mins_embed_head.offset_head.0.norm.{bias, running_mean, running_var, weight}
[34mins_embed_head.offset_head.0.weight
[34mins_embed_head.offset_head.1.norm.{bias, running_mean, running_var, weight}
[34mins_embed_head.offset_head.1.weight
[34mins_embed_head.offset_predictor.{bias, weight}
[34msem_seg_head.decoder.res2.fuse_conv.0.norm.{bias, running_mean, running_var, weight}
[34msem_seg_head.decoder.res2.fuse_conv.0.weight
[34msem_seg_head.decoder.res2.fuse_conv.1.norm.{bias, running_mean, running_var, weight}
[34msem_seg_head.decoder.res2.fuse_conv.1.weight
[34msem_seg_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}
[34msem_seg_head.decoder.res2.project_conv.weight
[34msem_seg_head.decoder.res3.fuse_conv.0.norm.{bias, running_mean, running_var, weight}
[34msem_seg_head.decoder.res3.fuse_conv.0.weight
[34msem_seg_head.decoder.res3.fuse_conv.1.norm.{bias, running_mean, running_var, weight}
[34msem_seg_head.decoder.res3.fuse_conv.1.weight
[34msem_seg_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}
[34msem_seg_head.decoder.res3.project_conv.weight
[34msem_seg_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}
[34msem_seg_head.decoder.res5.project_conv.convs.0.weight
[34msem_seg_head.decoder.res5.project_conv.convs.1.norm.{bias, running_mean, running_var, weight}
[34msem_seg_head.decoder.res5.project_conv.convs.1.weight
[34msem_seg_head.decoder.res5.project_conv.convs.2.norm.{bias, running_mean, running_var, weight}
[34msem_seg_head.decoder.res5.project_conv.convs.2.weight
[34msem_seg_head.decoder.res5.project_conv.convs.3.norm.{bias, running_mean, running_var, weight}
[34msem_seg_head.decoder.res5.project_conv.convs.3.weight
[34msem_seg_head.decoder.res5.project_conv.convs.4.1.{bias, weight}
[34msem_seg_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}
[34msem_seg_head.decoder.res5.project_conv.project.weight
[34msem_seg_head.head.0.norm.{bias, running_mean, running_var, weight}
[34msem_seg_head.head.0.weight
[34msem_seg_head.head.1.norm.{bias, running_mean, running_var, weight}
[34msem_seg_head.head.1.weight
[34msem_seg_head.predictor.{bias, weight}
[31m[5mWARNING[39m[25m [32m[08/07 13:10:37 fvcore.common.checkpoint]: [39mThe checkpoint state_dict contains keys that are not used by the model:
  [35mstem.fc.{bias, weight}
[32m[08/07 13:10:37 d2.engine.train_loop]: [39mStarting training from iteration 0
[32m[08/07 13:11:27 d2.utils.events]: [39m eta: 3 days, 1:33:00  iter: 19  total_loss: 14.24  loss_sem_seg: 2.203  loss_center: 11.75  loss_offset: 0.297    time: 1.3341  last_time: 1.3253  data_time: 1.3246  last_data_time: 0.1684   lr: 9.9896e-06  max_mem: 8671M
[32m[08/07 13:11:54 d2.utils.events]: [39m eta: 3 days, 2:07:29  iter: 39  total_loss: 13.89  loss_sem_seg: 2.18  loss_center: 11.43  loss_offset: 0.2934    time: 1.3465  last_time: 1.3354  data_time: 0.1805  last_data_time: 0.1422   lr: 1.9977e-05  max_mem: 8671M
[32m[08/07 13:12:21 d2.utils.events]: [39m eta: 3 days, 2:34:58  iter: 59  total_loss: 12.69  loss_sem_seg: 2.132  loss_center: 10.25  loss_offset: 0.2912    time: 1.3506  last_time: 1.3337  data_time: 0.1859  last_data_time: 0.1949   lr: 2.9963e-05  max_mem: 8672M
[32m[08/07 13:12:48 d2.utils.events]: [39m eta: 3 days, 3:06:45  iter: 79  total_loss: 11.42  loss_sem_seg: 2.031  loss_center: 9.101  loss_offset: 0.2928    time: 1.3549  last_time: 1.3818  data_time: 0.1840  last_data_time: 0.1895   lr: 3.9946e-05  max_mem: 8672M
[32m[08/07 13:13:15 d2.utils.events]: [39m eta: 3 days, 3:06:18  iter: 99  total_loss: 9.576  loss_sem_seg: 1.904  loss_center: 7.328  loss_offset: 0.2893    time: 1.3550  last_time: 1.4164  data_time: 0.1652  last_data_time: 0.1992   lr: 4.9928e-05  max_mem: 8672M
[32m[08/07 13:13:47 d2.utils.events]: [39m eta: 3 days, 3:28:27  iter: 119  total_loss: 7.23  loss_sem_seg: 1.765  loss_center: 5.179  loss_offset: 0.2883    time: 1.3939  last_time: 1.4956  data_time: 0.2483  last_data_time: 0.2594   lr: 5.9908e-05  max_mem: 8672M
[32m[08/07 13:14:19 d2.utils.events]: [39m eta: 3 days, 4:00:43  iter: 139  total_loss: 5.353  loss_sem_seg: 1.666  loss_center: 3.396  loss_offset: 0.2931    time: 1.4242  last_time: 1.5593  data_time: 0.2726  last_data_time: 0.2479   lr: 6.9887e-05  max_mem: 8672M
[32m[08/07 13:14:49 d2.utils.events]: [39m eta: 3 days, 4:36:08  iter: 159  total_loss: 3.89  loss_sem_seg: 1.547  loss_center: 2.04  loss_offset: 0.2806    time: 1.4299  last_time: 1.6687  data_time: 0.2411  last_data_time: 0.2771   lr: 7.9863e-05  max_mem: 8672M
[32m[08/07 13:15:22 d2.utils.events]: [39m eta: 3 days, 5:08:18  iter: 179  total_loss: 2.943  loss_sem_seg: 1.456  loss_center: 1.231  loss_offset: 0.2785    time: 1.4567  last_time: 1.8341  data_time: 0.2869  last_data_time: 0.2707   lr: 8.9838e-05  max_mem: 8672M
[32m[08/07 13:15:55 d2.utils.events]: [39m eta: 3 days, 6:33:53  iter: 199  total_loss: 2.554  loss_sem_seg: 1.344  loss_center: 0.8823  loss_offset: 0.2694    time: 1.4777  last_time: 1.7211  data_time: 0.3101  last_data_time: 0.1925   lr: 9.9811e-05  max_mem: 8672M
[31m[4m[5mERROR[39m[24m[25m [32m[08/07 13:16:02 d2.engine.train_loop]: [39mException during training:
Traceback (most recent call last):
  File "/home/liwa/project/OneFormer/detectron2/detectron2/engine/train_loop.py", line 155, in train
    self.run_step()
  File "/home/liwa/project/OneFormer/detectron2/detectron2/engine/defaults.py", line 498, in run_step
    self._trainer.run_step()
  File "/home/liwa/project/OneFormer/detectron2/detectron2/engine/train_loop.py", line 310, in run_step
    loss_dict = self.model(data)
  File "/home/liwa/miniconda3/envs/oneformer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/liwa/miniconda3/envs/oneformer/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 886, in forward
    output = self.module(*inputs[0], **kwargs[0])
  File "/home/liwa/miniconda3/envs/oneformer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/liwa/project/OneFormer/detectron2/projects/Panoptic-DeepLab/panoptic_deeplab/panoptic_seg.py", line 117, in forward
    sem_seg_results, sem_seg_losses = self.sem_seg_head(features, targets, weights)
  File "/home/liwa/miniconda3/envs/oneformer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/liwa/project/OneFormer/detectron2/projects/Panoptic-DeepLab/panoptic_deeplab/panoptic_seg.py", line 334, in forward
    y = self.layers(features)
  File "/home/liwa/project/OneFormer/detectron2/projects/Panoptic-DeepLab/panoptic_deeplab/panoptic_seg.py", line 345, in layers
    y = super().layers(features)
  File "/home/liwa/project/OneFormer/detectron2/projects/DeepLab/deeplab/semantic_seg.py", line 241, in layers
    proj_x = self.decoder[f]["project_conv"](x)
  File "/home/liwa/miniconda3/envs/oneformer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/liwa/project/OneFormer/detectron2/detectron2/layers/aspp.py", line 133, in forward
    raise ValueError(
ValueError: `pool_kernel_size` must be divisible by the shape of inputs. Input size: torch.Size([29, 29]) `pool_kernel_size`: (32, 32)
[32m[08/07 13:16:02 d2.engine.hooks]: [39mOverall training speed: 202 iterations in 0:04:59 (1.4833 s / it)
[32m[08/07 13:16:02 d2.engine.hooks]: [39mTotal training time: 0:04:59 (0:00:00 on hooks)
[32m[08/07 13:16:02 d2.utils.events]: [39m eta: 3 days, 6:36:46  iter: 204  total_loss: 2.465  loss_sem_seg: 1.319  loss_center: 0.8623  loss_offset: 0.2632    time: 1.4811  last_time: 1.6708  data_time: 0.2926  last_data_time: 0.3307   lr: 0.00010181  max_mem: 8672M